{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GrEx1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/af001/Predictive-Analytics/blob/master/MSDS420/GrEx1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFUK3DbrF-qU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download data\n",
        "#!wget https://data.sfgov.org/api/views/xr4w-bx78/rows.csv?accessType=DOWNLOAD&bom=true&format=true -O 2014_SFO_Customer_Survey.csv\n",
        "#!wget https://data.sfgov.org/api/views/t3vr-buhp/rows.csv?accessType=DOWNLOAD&bom=true&format=true -O 2016_SFO_Customer_Survey.csv\n",
        "#!wget https://data.sfgov.org/api/views/6h3c-wyfe/rows.csv?accessType=DOWNLOAD&bom=true&format=true -O 2015_SFO_Customer_Survey.csv\n",
        "!mkdir outfiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMRL2P0rAixi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89a01799-76fa-4671-fa5d-09b50ec75933"
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# Assignment: GrEx1\n",
        "# Author: Anton\n",
        "# Date: 20170630\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from platform import system as system_name \n",
        "from os import system as system_call \n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Define global variables\n",
        "renamed_columns = []\n",
        "col_names_2016 = []\n",
        "col_names_2015  = []\n",
        "col_names_2014 = []\n",
        "com_df_2016 = pd.DataFrame()\n",
        "com_df_2015 = pd.DataFrame()\n",
        "user_df_2016 = pd.DataFrame()\n",
        "user_df_2015 = pd.DataFrame()\n",
        "\n",
        "def parse_files():\n",
        "    # Read the excel files to a dataframe sfo 2017_data file_final_weighted.xlsx\n",
        "    #xl1_2016 = pd.ExcelFile('2016_SFO_Customer_Survey_Data.xlsx')\n",
        "    #xl2_2014 = pd.ExcelFile('2014_SFO_Customer_Survey.xlsx')\n",
        "    \n",
        "    # Read csv files, take all files and create a dataframe of the data\n",
        "    df_2014 = pd.read_csv('2014_SFO_Customer_Survey.csv')\n",
        "    df_2015 = pd.read_csv('2015_SFO_Customer_Survey.csv')\n",
        "    df_2016 = pd.read_csv('2016_SFO_Customer_Survey.csv')\n",
        "    #df_2016 = xl1_2016.parse('Data')\n",
        "    #df_2014 = xl2_2014.parse('Sheet 1')\n",
        "    \n",
        "    # Parse the required columns and store them in separate frames\n",
        "    df_2016 = parse_2016(df_2016)\n",
        "    df_2015 = parse_2015(df_2015)\n",
        "    df_2014 = parse_2014(df_2014)\n",
        "    \n",
        "    # Use append to combine dataframes for each year of SFO data\n",
        "    final_df = df_2016.append(df_2015, ignore_index=True)\n",
        "    final_df = final_df.append(df_2014, ignore_index=True)\n",
        "    \n",
        "    # Fill 'Blank' and 0 values with NaN for consistency\n",
        "    final_df.fillna(np.nan, inplace=True)\n",
        "    final_df.replace('Blank', np.nan, inplace=True)\n",
        "    \n",
        "    # Display integers, not floats \n",
        "    pd.options.display.float_format = '{:,.0f}'.format\n",
        "    \n",
        "    return final_df\n",
        "    \n",
        "def get_columns(df):\n",
        "    # Get column names --> aka variables\n",
        "    headers = [col.encode('ascii', 'ignore') for col in df]\n",
        "    return headers\n",
        "          \n",
        "def parse_2016(df_2016):\n",
        "    global renamed_columns\n",
        "    global com_df_2016\n",
        "    global user_df_2016\n",
        "    global col_names_2016\n",
        "    \n",
        "    # Define column names to filter from main dataframe\n",
        "    col_names_2016 = ['*RESPNUM','Q7ART','Q7FOOD','Q7STORE','Q7SIGN',\n",
        "    'Q7WALKWAYS','Q7SCREENS','Q7INFODOWN','Q7INFOUP','Q7WIFI','Q7ROADS',\n",
        "    'Q7PARK','Q7AIRTRAIN','Q7LTPARKING','Q7RENTAL','Q7ALL','Q9BOARDING',\n",
        "    'Q9AIRTRAIN','Q9RENTAL','Q9FOOD','Q9RESTROOM','Q9ALL','Q10SAFE',\n",
        "    'Q12PRECHECKRATE','Q13GETRATE','Q14FIND','Q14PASSTHRU','Q16LIVE']\n",
        "    \n",
        "    # Filter the variables, replace improperly named variables, and append\n",
        "    # the year to the column list\n",
        "    df = df_2016.filter(col_names_2016, axis=1)\n",
        "    df.rename(columns = {'*RESPNUM':'RESPNUM'}, inplace = True)\n",
        "    df['YEAR'] = 2016\n",
        "    renamed_columns.append('2016  :  \\'*RESPNUM\\' --> \\'RESPNUM\\'')\n",
        "    \n",
        "    # Parse Part II data and store it\n",
        "    com_columns = ['Q8COM', 'Q8COM2', 'Q8COM3', 'Q8COM4', 'Q8COM5']\n",
        "    com_df_2016 = df_2016.filter(com_columns, axis=1)\n",
        "    \n",
        "    # Replace non-integer variables for filtering Part IV data\n",
        "    df_2016.replace({'Male':1,'Female':2,'Other':3}, inplace=True)\n",
        "    df_2016.replace({'Under 18':1,'18-24': 2,'25-34':3,'35-44':4,'45-54':5,\n",
        "    '55-64':6,'65-Over':7,'Don\\'t Know or Refused':8,'Under 32':0,'Under 30':0,\n",
        "    'Under 29':0,'Under 28':0,'Under 27':0,'Under 26':0,'Under 25':0,\n",
        "    'Under 24':0,'Under 23':0,'Under 22':0,'Under 21':0,'Under 20':0,\n",
        "    'Under 19':0,'Under 31':0}, inplace=True)\n",
        "    \n",
        "    # Parse Part IV data and store it. Add year column\n",
        "    user_columns = ['*RESPNUM','INTDATE','DESTGEO','DESTMARK','Q2PURP1','Q2PURP2',\n",
        "    'Q2PURP3','Q3GETTO1','Q3GETTO2','Q3GETTO3','Q3PARK','Q4BAGS','Q4STORE',\n",
        "    'Q4FOOD','Q4WIFI','Q5TIMESFLOWN','Q5FIRSTTIME','Q6LONGUSE','Q16LIVE',\n",
        "    'Q17CITY','Q17STATE','Q17ZIP','Q17COUNTRY','HOME','Q18PET','Q19AGE',\n",
        "    'Q20GENDER','Q21INCME','Q22FLY','Q23SJC','Q23OAK','LANG']\n",
        "   \n",
        "    user_df_2016 = df_2016.filter(user_columns, axis=1)\n",
        "    user_df_2016.rename(columns = {'*RESPNUM':'RESPNUM'}, inplace = True)\n",
        "    user_df_2016['YEAR'] = 2016\n",
        "        \n",
        "    return df\n",
        "    \n",
        "def parse_2015(df_2015):\n",
        "    global renamed_columns\n",
        "    global col_names_2015\n",
        "    global user_df_2015\n",
        "    global com_df_2015\n",
        "    \n",
        "    # Define column names to filter from main dataframe\n",
        "    col_names_2015 = ['RESPNUM','Q7ART','Q7FOOD','Q7STORE','Q7SIGN',\n",
        "    'Q7WALKWAYS','Q7SCREENS','Q7INFODOWN','Q7INFOUP','Q7WIFI','Q7ROADS',\n",
        "    'Q7PARK','Q7AIRTRAIN','Q7LTPARKING','Q7RENTAL','Q7ALL','Q9BOARDING',\n",
        "    'Q9AIRTRAIN','Q9RENTAL','Q9FOOD','Q9RESTROOM','Q9ALL','Q10SAFE',\n",
        "    'Q12PRECHEKCRATE','Q13GETRATE','Q14FIND','Q14PASSTHRU','Q16LIVE']\n",
        "\n",
        "    # Filter the variables, replace improperly named variables, and append\n",
        "    # the year to the column list\n",
        "    df = df_2015.filter(col_names_2015, axis=1)\n",
        "    df.rename(columns = {'Q12PRECHEKCRATE':'Q12PRECHECKRATE'}, inplace = True)\n",
        "    df['YEAR'] = 2015\n",
        "    renamed_columns.append('2015  :  \\'Q12PRECHEKCRATE\\' --> \\'Q12PRECHECKRATE\\'')\n",
        "    \n",
        "    # Parse Part II data and store it\n",
        "    com_columns = ['Q8COM1', 'Q8COM2', 'Q8COM3']\n",
        "    com_df_2015 = df_2015.filter(com_columns, axis=1)\n",
        "    \n",
        "    # Define Part IV data, filter, rename, and store\n",
        "    user_columns = ['RESPNUM','INTDATE','DESTGEO','DESTMARK','Q2PURP1',\n",
        "    'Q2PURP2','Q2PURP3','Q3GETTO1','Q3GETTO2','Q3GETTO3','Q3PARK','Q4BAGS',\n",
        "    'Q4STORE','Q4FOOD','Q4WIFI','Q5TIMESFLOWN','Q5FIRSTTIME','Q6LONGUSE',\n",
        "    'Q16LIVE','HOME','Q17CITY','Q17STATE','Q17ZIP','Q17COUNTRY','Q18AGE',\n",
        "    'Q19GENDER','Q20INCOME','Q21FLY','Q22SJC','Q22OAK','LANG']\n",
        "    user_df_2015 = df_2015.filter(user_columns, axis=1)\n",
        "    user_df_2015.rename(columns = {'Q18AGE':'Q19AGE','Q19GENDER':'Q20GENDER',\n",
        "    'Q20INCOME':'Q21INCME','Q21FLY':'Q22FLY','Q22SJC':'Q23SJC',\n",
        "    'Q22OAK':'Q23OAK'}, inplace = True)\n",
        "    user_df_2015['Q18PET'] = 5\n",
        "    user_df_2015['YEAR'] = 2015\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_2014(df_2014):\n",
        "    global col_names_2014\n",
        "    col_names_2014 = ['RESPNUM','Q7ART','Q7FOOD','Q7STORE','Q7SIGN',\n",
        "    'Q7WALKWAYS','Q7SCREENS','Q7INFODOWN','Q7INFOUP','Q7WIFI','Q7ROADS',\n",
        "    'Q7PARK','Q7AIRTRAIN','Q7LTPARKING','Q7RENTAL','Q7ALL','Q9BOARDING',\n",
        "    'Q9AIRTRAIN','Q9RENTAL','Q9FOOD','Q9RESTROOM','Q9ALL','Q10SAFE',\n",
        "    'Q12PRECHECKRATE','Q13GETRATE','Q14FIND','Q14PASSTHRU','Q16LIVE']\n",
        "    \n",
        "    df = df_2014.filter(col_names_2014, axis=1)\n",
        "    df['YEAR'] = 2015\n",
        "    \n",
        "    return df\n",
        "    \n",
        "def organize_data(df):\n",
        "    # Organize the columns before writing to file. \n",
        "    df = df[['RESPNUM', 'YEAR', 'Q16LIVE', 'Q7ART', 'Q7FOOD', 'Q7STORE', 'Q7SIGN', \n",
        "             'Q7WALKWAYS', 'Q7SCREENS', 'Q7INFODOWN', 'Q7INFOUP', 'Q7WIFI', 'Q7ROADS', \n",
        "             'Q7PARK', 'Q7AIRTRAIN', 'Q7LTPARKING', 'Q7RENTAL', 'Q7ALL', 'Q9BOARDING', \n",
        "             'Q9AIRTRAIN', 'Q9RENTAL', 'Q9FOOD', 'Q9RESTROOM', 'Q9ALL', 'Q10SAFE', \n",
        "             'Q12PRECHECKRATE', 'Q13GETRATE', 'Q14FIND', 'Q14PASSTHRU']]  \n",
        "    return df\n",
        "    \n",
        "def print_summary(section, df):\n",
        "    count = 4\n",
        "    cols = {2016:col_names_2016,2015:col_names_2015,2014:col_names_2014}\n",
        "    add_cols = ['2016','2015','2014']\n",
        "    \n",
        "    # Statements for displaying data, show renamed columns\n",
        "    if section == 1:\n",
        "        print '[+] Renamed Columns:'\n",
        "        for col in renamed_columns:\n",
        "            print '\\t%s' % col\n",
        "    # Show original variable names \n",
        "    elif section == 2:  \n",
        "        for year, col in cols.iteritems():\n",
        "            print '[+] %s Variable Names: [Count = %s]' % (year,len(col))\n",
        "            for ix in col:\n",
        "                if count > 0:\n",
        "                    print '\\t%-13s|' % ix,\n",
        "                    count-=1\n",
        "                else:\n",
        "                    print '\\n\\t%-13s|' % ix,\n",
        "                    count=3\n",
        "            count = 4\n",
        "            print '\\n'\n",
        "    # Show table to show the meaning of codes used for SFO data. Pretty print\n",
        "    # the data in a table.\n",
        "    elif section == 3:\n",
        "        describe_dataset(df)\n",
        "        legend1={5:['Outstanding', 'Clean', 'Safe', 'Much Better', 'Easy'],\n",
        "        4:['', '', '', 'Somewhat Better', ''],3:['', 'Average', 'Neutral', \n",
        "        'Same', 'Average'],2:['', '', '', 'Somewhat Worse', ''],\n",
        "        1:['Unacceptable', 'Dirty', 'Not Safe', 'Much Worse', \n",
        "        'Difficult'],6:['NA', 'NA', 'Don\\'t Know', 'NA', 'NA']}\n",
        "        legend2={1:'County Bay Area',2:'Northern California outside the Bay Area',\n",
        "        3:'In another region'}\n",
        "        \n",
        "        # Prety print the tables\n",
        "        table = PrettyTable(['Rating', 'Q7', 'Q9', 'Q10', 'Q12', 'Q13:Q14'])       \n",
        "        for rating, desc in legend1.iteritems(): \n",
        "            table.add_row([rating,desc[0],desc[1],desc[2],desc[3],desc[4]])         \n",
        "        \n",
        "        print '\\n[+] Coding:\\n', table, '\\n'\n",
        "              \n",
        "        table = PrettyTable(['Code', 'Live in...'])\n",
        "        for rating,desc in legend2.iteritems():\n",
        "            table.add_row([rating,desc[0:]]) \n",
        "        print table  \n",
        "    # Show years that had columns added (2016,2015,2014 data)\n",
        "    elif section == 4:\n",
        "        print '\\n[+] Added Columns: '\n",
        "        for col in add_cols:\n",
        "            print '\\t%s  :  \\'YEAR\\'' % col      \n",
        "    # Show variables used for part IV\n",
        "    elif section == 5:\n",
        "        describe_dataset(df)\n",
        "        print '\\n[+] Combined Variables:' \n",
        "        for ix in get_columns(df):\n",
        "                if count > 0:\n",
        "                    print '\\t%-13s|' % ix,\n",
        "                    count-=1\n",
        "                else:\n",
        "                    print '\\n\\t%-13s|' % ix,\n",
        "                    count=3  \n",
        "        print '\\n'\n",
        "        \n",
        "def describe_dataset(df):\n",
        "    # Print description of dataframe. Could use df.describe, but result doesn't\n",
        "    # describe the physical characteristics of the data, as requested. \n",
        "    print '\\n[+] Dataframe Description:'\n",
        "    print '\\tDimentions: %s x %s (Rows x Columns)' % (str(len(df.index)), \n",
        "                                                          str(len(get_columns(df))))\n",
        "    print '\\tEntries: %s' % (len(df.index) * len(get_columns(df)))\n",
        "    print '\\tMissing/NA/Blank Responses: %s' % sum(df.isnull().sum(axis=0))\n",
        "\n",
        "def start_program():\n",
        "    # Clear command as function of OS. Shows fresh screen on start\n",
        "    command = \"-cls\" if system_name().lower()==\"windows\" else \"clear\"\n",
        "    system_call(command)\n",
        "    \n",
        "    print '[+] GrrExercise #1: Anton Foltz'\n",
        "    print '[+] Predict420 - Northwestern'\n",
        "    print '[+] June 28, 2017\\n'\n",
        "\n",
        "def do_partI():\n",
        "    # Part I functions. Used to parse, display, pickle, and store data to file\n",
        "    parsed_data = parse_files()\n",
        "    parsed_data = organize_data(parsed_data)\n",
        "    print_summary(2, None)\n",
        "    print_summary(1, None)\n",
        "    print_summary(4, None)\n",
        "    print_summary(3, parsed_data)\n",
        "    parsed_data.to_csv('outfiles/out.csv', encoding='utf-8')\n",
        "    parsed_data.to_pickle('outfiles/sfo_pickle.pkl')\n",
        "    return parsed_data\n",
        "\n",
        "def get_top_comments(df):\n",
        "    # Get top 3 comments\n",
        "    codes = {103:'Going through security takes too long/add more checkpoints',\n",
        "    202:'Need more places to eat/drink/more variety in types of restaurants', \n",
        "    999:'Good experience/keep up the good work/other positive comment'}\n",
        "    \n",
        "    # Unstack the dataframe to make one column; then count\n",
        "    unstack = df.unstack(level=0)\n",
        "    counts = unstack.value_counts()\n",
        "    print '\\n[+] Top Comments: [Format = Count - [Code] Comment]'\n",
        "    counts = counts.head(n=3)\n",
        "\n",
        "    # Iterate over list and pretty print the output to stdout\n",
        "    for row in counts.index.tolist():\n",
        "        print '\\t%s - [%s] %s' % (counts[row], int(row), codes[int(row)])\n",
        "\n",
        "def do_partII():\n",
        "    # Part II functions. Used to parse, display, and pickle the dataframe\n",
        "    df = com_df_2016.append(com_df_2015, ignore_index=True)\n",
        "    df.replace(0, np.nan, inplace=True)\n",
        "    get_top_comments(df)\n",
        "    df.to_pickle('outfiles/sfo_pickle.pkl')\n",
        "    \n",
        "def find_location_trend(df):\n",
        "    # Get count of overall assessment by respondent residence\n",
        "    codes = {1:'County Bay Area', 2:'Northern California outside the Bay Arera', \n",
        "    3:'In another region', 0:'Blank/Multiple Responses'}\n",
        "    \n",
        "    # Count the frequency, and pretty print the results to the screen.\n",
        "    print ('\\n[+] Assessment By Respondent Residence: [Format = Count - [Code] Residence]')\n",
        "    counts = df.groupby([\"Q16LIVE\"]).count()    \n",
        "    for row,ix in zip(counts['Q7ALL'],range(3)):\n",
        "        print '\\t%s - [%s] %s' % (int(row), ix+1, codes[ix+1])\n",
        "        \n",
        "def get_targeted_users(df):\n",
        "    # Read selected respondents file and extract respondents from main dataframe\n",
        "    targets = pd.read_csv('select_resps.csv')\n",
        "    targets.rename(columns = {'year':'YEAR'}, inplace = True)\n",
        "    targets['RESPNUM'] = targets['RESPNUM'].astype(object)\n",
        "    df = pd.merge(df, targets, on=['YEAR', 'RESPNUM'], how='inner')    \n",
        "    return df\n",
        "    \n",
        "def count_frequency(df):\n",
        "    # Part IV frequency counter. Define data to count\n",
        "    columns = ['Q3PARK','Q5TIMESFLOWN','Q6LONGUSE']\n",
        "    titles = ['[+] Parking:','\\n[+] Times Flown:','\\n[+] SFO Usage']\n",
        "    parking = {1:'Domestic (hourly) garage',2:'International garage',\n",
        "    3:'SFO long term parking',4: 'Off-airport parking'}\n",
        "    flown = {1:'1 time',2:'2 times',3:'3-6 times',4:'7-12 times',\n",
        "    5:'13-24 times',6:'More than 24 times'}\n",
        "    use = {1:'Less than 1 year [0.5]',2:'1-5 years [3]',\n",
        "    3: '6-10 years [8]',4:'10+ years [15]'}\n",
        "    \n",
        "    # Do some magic using nested for statements. Display results of the frequency\n",
        "    # counter\n",
        "    df.replace(0, np.nan, inplace=True)\n",
        "    for item,ix in zip(columns,range(3)):\n",
        "        counts = df[item].value_counts()\n",
        "        shouldPrint = True\n",
        "        for iz,iw in counts.iteritems():\n",
        "            if shouldPrint:\n",
        "                print '%s' % titles[ix]\n",
        "                shouldPrint = False\n",
        "            if ix == 0:\n",
        "                print '\\t%s - [%s] %s' % (iw,int(iz),parking[iz])\n",
        "            elif ix == 1:\n",
        "                print '\\t%s - [%s] %s' % (iw,int(iz),flown[iz])\n",
        "            elif ix == 2:\n",
        "                print '\\t%s - [%s] %s' % (iw,int(iz),use[iz])\n",
        "        shouldPrint = True\n",
        "    \n",
        "def do_partIII(df):\n",
        "    # Main functions used to display part III data. Filter, parse, display, pickle.\n",
        "    parsed_data = df.filter(['Q7ALL','Q16LIVE'], axis=1)\n",
        "    parsed_data.replace(4, 3, inplace=True)\n",
        "    find_location_trend(parsed_data)\n",
        "    parsed_data.to_pickle('outfiles/sfo_pickle.pkl')\n",
        "    \n",
        "def do_partIV():\n",
        "    # Main functions to filter, parse, display, pickle, and store part IV data\n",
        "    df = user_df_2016.append(user_df_2015)\n",
        "    df.replace(0, np.nan, inplace=True)\n",
        "    parsed_data = get_targeted_users(df)\n",
        "    print_summary(5, parsed_data)\n",
        "    parsed_data.to_csv('outfiles/sfo_partIV_out.csv', encoding='utf-8')\n",
        "    parsed_data = parsed_data.filter(['Q3PARK','Q5TIMESFLOWN','Q6LONGUSE'], axis=1)\n",
        "    count_frequency(parsed_data)\n",
        "    parsed_data.to_pickle('outfiles/sfo_pickle.pkl')\n",
        "    \n",
        "def main():\n",
        "    # Main function. Launch functions for part I, II, II, IV\n",
        "    start_program()\n",
        "    partI_data = do_partI()\n",
        "    do_partII()\n",
        "    do_partIII(partI_data)\n",
        "    do_partIV()\n",
        "    print partI_data.head()\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] GrrExercise #1: Anton Foltz\n",
            "[+] Predict420 - Northwestern\n",
            "[+] June 28, 2017\n",
            "\n",
            "[+] 2016 Variable Names: [Count = 28]\n",
            "\t*RESPNUM     | \tQ7ART        | \tQ7FOOD       | \tQ7STORE      | \n",
            "\tQ7SIGN       | \tQ7WALKWAYS   | \tQ7SCREENS    | \tQ7INFODOWN   | \n",
            "\tQ7INFOUP     | \tQ7WIFI       | \tQ7ROADS      | \tQ7PARK       | \n",
            "\tQ7AIRTRAIN   | \tQ7LTPARKING  | \tQ7RENTAL     | \tQ7ALL        | \n",
            "\tQ9BOARDING   | \tQ9AIRTRAIN   | \tQ9RENTAL     | \tQ9FOOD       | \n",
            "\tQ9RESTROOM   | \tQ9ALL        | \tQ10SAFE      | \tQ12PRECHECKRATE| \n",
            "\tQ13GETRATE   | \tQ14FIND      | \tQ14PASSTHRU  | \tQ16LIVE      | \n",
            "\n",
            "[+] 2014 Variable Names: [Count = 28]\n",
            "\tRESPNUM      | \tQ7ART        | \tQ7FOOD       | \tQ7STORE      | \n",
            "\tQ7SIGN       | \tQ7WALKWAYS   | \tQ7SCREENS    | \tQ7INFODOWN   | \n",
            "\tQ7INFOUP     | \tQ7WIFI       | \tQ7ROADS      | \tQ7PARK       | \n",
            "\tQ7AIRTRAIN   | \tQ7LTPARKING  | \tQ7RENTAL     | \tQ7ALL        | \n",
            "\tQ9BOARDING   | \tQ9AIRTRAIN   | \tQ9RENTAL     | \tQ9FOOD       | \n",
            "\tQ9RESTROOM   | \tQ9ALL        | \tQ10SAFE      | \tQ12PRECHECKRATE| \n",
            "\tQ13GETRATE   | \tQ14FIND      | \tQ14PASSTHRU  | \tQ16LIVE      | \n",
            "\n",
            "[+] 2015 Variable Names: [Count = 28]\n",
            "\tRESPNUM      | \tQ7ART        | \tQ7FOOD       | \tQ7STORE      | \n",
            "\tQ7SIGN       | \tQ7WALKWAYS   | \tQ7SCREENS    | \tQ7INFODOWN   | \n",
            "\tQ7INFOUP     | \tQ7WIFI       | \tQ7ROADS      | \tQ7PARK       | \n",
            "\tQ7AIRTRAIN   | \tQ7LTPARKING  | \tQ7RENTAL     | \tQ7ALL        | \n",
            "\tQ9BOARDING   | \tQ9AIRTRAIN   | \tQ9RENTAL     | \tQ9FOOD       | \n",
            "\tQ9RESTROOM   | \tQ9ALL        | \tQ10SAFE      | \tQ12PRECHEKCRATE| \n",
            "\tQ13GETRATE   | \tQ14FIND      | \tQ14PASSTHRU  | \tQ16LIVE      | \n",
            "\n",
            "[+] Renamed Columns:\n",
            "\t2016  :  '*RESPNUM' --> 'RESPNUM'\n",
            "\t2015  :  'Q12PRECHEKCRATE' --> 'Q12PRECHECKRATE'\n",
            "\n",
            "[+] Added Columns: \n",
            "\t2016  :  'YEAR'\n",
            "\t2015  :  'YEAR'\n",
            "\t2014  :  'YEAR'\n",
            "\n",
            "[+] Dataframe Description:\n",
            "\tDimentions: 8863 x 29 (Rows x Columns)\n",
            "\tEntries: 257027\n",
            "\tMissing/NA/Blank Responses: 3927\n",
            "\n",
            "[+] Coding:\n",
            "+--------+--------------+---------+------------+-----------------+-----------+\n",
            "| Rating |      Q7      |    Q9   |    Q10     |       Q12       |  Q13:Q14  |\n",
            "+--------+--------------+---------+------------+-----------------+-----------+\n",
            "|   1    | Unacceptable |  Dirty  |  Not Safe  |    Much Worse   | Difficult |\n",
            "|   2    |              |         |            |  Somewhat Worse |           |\n",
            "|   3    |              | Average |  Neutral   |       Same      |  Average  |\n",
            "|   4    |              |         |            | Somewhat Better |           |\n",
            "|   5    | Outstanding  |  Clean  |    Safe    |   Much Better   |    Easy   |\n",
            "|   6    |      NA      |    NA   | Don't Know |        NA       |     NA    |\n",
            "+--------+--------------+---------+------------+-----------------+-----------+ \n",
            "\n",
            "+------+------------------------------------------+\n",
            "| Code |                Live in...                |\n",
            "+------+------------------------------------------+\n",
            "|  1   |             County Bay Area              |\n",
            "|  2   | Northern California outside the Bay Area |\n",
            "|  3   |            In another region             |\n",
            "+------+------------------------------------------+\n",
            "\n",
            "[+] Top Comments: [Format = Count - [Code] Comment]\n",
            "\t385 - [999] Good experience/keep up the good work/other positive comment\n",
            "\t307 - [202] Need more places to eat/drink/more variety in types of restaurants\n",
            "\t168 - [103] Going through security takes too long/add more checkpoints\n",
            "\n",
            "[+] Assessment By Respondent Residence: [Format = Count - [Code] Residence]\n",
            "\t325 - [1] County Bay Area\n",
            "\t2876 - [2] Northern California outside the Bay Arera\n",
            "\t420 - [3] In another region\n",
            "\n",
            "[+] Dataframe Description:\n",
            "\tDimentions: 0 x 33 (Rows x Columns)\n",
            "\tEntries: 0\n",
            "\tMissing/NA/Blank Responses: 0\n",
            "\n",
            "[+] Combined Variables:\n",
            "\tDESTGEO      | \tDESTMARK     | \tHOME         | \tINTDATE      | \n",
            "\tLANG         | \tQ16LIVE      | \tQ17CITY      | \tQ17COUNTRY   | \n",
            "\tQ17STATE     | \tQ17ZIP       | \tQ18PET       | \tQ19AGE       | \n",
            "\tQ20GENDER    | \tQ21INCME     | \tQ22FLY       | \tQ23OAK       | \n",
            "\tQ23SJC       | \tQ2PURP1      | \tQ2PURP2      | \tQ2PURP3      | \n",
            "\tQ3GETTO1     | \tQ3GETTO2     | \tQ3GETTO3     | \tQ3PARK       | \n",
            "\tQ4BAGS       | \tQ4FOOD       | \tQ4STORE      | \tQ4WIFI       | \n",
            "\tQ5FIRSTTIME  | \tQ5TIMESFLOWN | \tQ6LONGUSE    | \tRESPNUM      | \n",
            "\tYEAR         | \n",
            "\n",
            "  RESPNUM  YEAR  Q16LIVE  ...  Q13GETRATE  Q14FIND  Q14PASSTHRU\n",
            "0      17  2016        3  ...           3        3            2\n",
            "1      70  2016        3  ...           3        5            5\n",
            "2   1,512  2016        3  ...           5        5            5\n",
            "3   1,932  2016        3  ...           6        4            6\n",
            "4   2,408  2016        3  ...           5        5            5\n",
            "\n",
            "[5 rows x 29 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxdJ56iLCuGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cfe7237-30f2-4b37-b084-95b5a545a1c7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}